{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "bab978a4d9bc483f0697223cca084e52213fdf00"
   },
   "source": [
    "# Case 1 - Santander - Tunning Hiper-Parametros do Modelo Original\n",
    "## Marcio de Lima"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "9e67cd962fd4fb67f0daf0b1db26a91d22f788bc"
   },
   "source": [
    "<img style=\"float: left;\" src=\"https://guardian.ng/wp-content/uploads/2016/08/Heart-diseases.jpg\" width=\"350px\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns #for plotting\n",
    "from sklearn.ensemble import RandomForestClassifier #for the model\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.tree import export_graphviz #plot tree\n",
    "from sklearn.metrics import roc_curve, auc #for model evaluation\n",
    "from sklearn.metrics import classification_report #for model evaluation\n",
    "from sklearn.metrics import confusion_matrix #for model evaluation\n",
    "from sklearn.model_selection import train_test_split #for data splitting\n",
    "import eli5 #for purmutation importance\n",
    "from eli5.sklearn import PermutationImportance\n",
    "import shap #for SHAP values\n",
    "from pdpbox import pdp, info_plots #for partial plots\n",
    "np.random.seed(123) #ensure reproducibility\n",
    "\n",
    "pd.options.mode.chained_assignment = None  #hide any pandas warnings\n",
    "\n",
    "#Marcio de Lima\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "87aec28b7dd55601a7363cb7b613907e98f24518"
   },
   "source": [
    "<a id='section2'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "78d63e79cfb6f48e78dab7c785e8e952a08d518c"
   },
   "source": [
    "# The Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "dt = pd.read_csv(\"../dados/heart.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_uuid": "f3caf3de0a7e6d4602b26a1e72bf42d42ef0aac0"
   },
   "outputs": [],
   "source": [
    "dt.columns = ['age', 'sex', 'chest_pain_type', 'resting_blood_pressure', 'cholesterol', 'fasting_blood_sugar', 'rest_ecg', 'max_heart_rate_achieved',\n",
    "       'exercise_induced_angina', 'st_depression', 'st_slope', 'num_major_vessels', 'thalassemia', 'target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_uuid": "755235c8db67e5d76ee2fdc5cd55390e60e61ee9"
   },
   "outputs": [],
   "source": [
    "dt['sex'][dt['sex'] == 0] = 'female'\n",
    "dt['sex'][dt['sex'] == 1] = 'male'\n",
    "\n",
    "dt['chest_pain_type'][dt['chest_pain_type'] == 1] = 'typical angina'\n",
    "dt['chest_pain_type'][dt['chest_pain_type'] == 2] = 'atypical angina'\n",
    "dt['chest_pain_type'][dt['chest_pain_type'] == 3] = 'non-anginal pain'\n",
    "dt['chest_pain_type'][dt['chest_pain_type'] == 4] = 'asymptomatic'\n",
    "\n",
    "dt['fasting_blood_sugar'][dt['fasting_blood_sugar'] == 0] = 'lower than 120mg/ml'\n",
    "dt['fasting_blood_sugar'][dt['fasting_blood_sugar'] == 1] = 'greater than 120mg/ml'\n",
    "\n",
    "dt['rest_ecg'][dt['rest_ecg'] == 0] = 'normal'\n",
    "dt['rest_ecg'][dt['rest_ecg'] == 1] = 'ST-T wave abnormality'\n",
    "dt['rest_ecg'][dt['rest_ecg'] == 2] = 'left ventricular hypertrophy'\n",
    "\n",
    "dt['exercise_induced_angina'][dt['exercise_induced_angina'] == 0] = 'no'\n",
    "dt['exercise_induced_angina'][dt['exercise_induced_angina'] == 1] = 'yes'\n",
    "\n",
    "dt['st_slope'][dt['st_slope'] == 1] = 'upsloping'\n",
    "dt['st_slope'][dt['st_slope'] == 2] = 'flat'\n",
    "dt['st_slope'][dt['st_slope'] == 3] = 'downsloping'\n",
    "\n",
    "dt['thalassemia'][dt['thalassemia'] == 1] = 'normal'\n",
    "dt['thalassemia'][dt['thalassemia'] == 2] = 'fixed defect'\n",
    "dt['thalassemia'][dt['thalassemia'] == 3] = 'reversable defect'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "_uuid": "12edd841e271a4f7c8c039aa73412c0d6d7e5dad"
   },
   "outputs": [],
   "source": [
    "dt['sex'] = dt['sex'].astype('object')\n",
    "dt['chest_pain_type'] = dt['chest_pain_type'].astype('object')\n",
    "dt['fasting_blood_sugar'] = dt['fasting_blood_sugar'].astype('object')\n",
    "dt['rest_ecg'] = dt['rest_ecg'].astype('object')\n",
    "dt['exercise_induced_angina'] = dt['exercise_induced_angina'].astype('object')\n",
    "dt['st_slope'] = dt['st_slope'].astype('object')\n",
    "dt['thalassemia'] = dt['thalassemia'].astype('object')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "_uuid": "b6ec4deb644854301fa463758df32d6171f1c615"
   },
   "outputs": [],
   "source": [
    "dt = pd.get_dummies(dt, drop_first=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "58c7f30375a2ffb7e02763e249e441a12cd437f1"
   },
   "source": [
    "# The Model\n",
    "\n",
    "The next part fits a random forest model to the data,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "_uuid": "315ebc70bfe105f4b224974415db867d3d1e6b66"
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(dt.drop('target', 1), dt['target'], test_size = .2, random_state=10) #split the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "_uuid": "6169b0b96267bea8bd8c35d64470d634edd79d78"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "                       max_depth=5, max_features='auto', max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=10,\n",
       "                       n_jobs=None, oob_score=False, random_state=None,\n",
       "                       verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = RandomForestClassifier(max_depth=5)\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "_uuid": "c215bcb6b80e12905f54b6a33620b6514d1e915a"
   },
   "outputs": [],
   "source": [
    "y_predict = model.predict(X_test)\n",
    "y_pred_quant = model.predict_proba(X_test)\n",
    "y_pred_bin = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "_uuid": "a0fe6269405b8404a60fd656ee2940f50cc4c0d3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[28,  7],\n",
       "       [ 3, 23]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix = confusion_matrix(y_test, y_pred_bin)\n",
    "confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "_uuid": "fcd6e81d7fdfae6571aee37f210cbd6f15da1a8a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sensitivity :  0.9032258064516129\n",
      "Specificity :  0.7666666666666667\n"
     ]
    }
   ],
   "source": [
    "total=sum(sum(confusion_matrix))\n",
    "\n",
    "sensitivity = confusion_matrix[0,0]/(confusion_matrix[0,0]+confusion_matrix[1,0])\n",
    "print('Sensitivity : ', sensitivity )\n",
    "\n",
    "specificity = confusion_matrix[1,1]/(confusion_matrix[1,1]+confusion_matrix[0,1])\n",
    "print('Specificity : ', specificity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of RandomForest Regression Classifier on train set: 92.15\n",
      "Accuracy of RandomForest Regression Classifier on test set: 83.61\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy of RandomForest Regression Classifier on train set: {:.2f}'.format(model.score(X_train, y_train)*100))\n",
    "print('Accuracy of RandomForest Regression Classifier on test set: {:.2f}'.format(model.score(X_test, y_test)*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.80      0.85        35\n",
      "           1       0.77      0.88      0.82        26\n",
      "\n",
      "    accuracy                           0.84        61\n",
      "   macro avg       0.83      0.84      0.83        61\n",
      "weighted avg       0.85      0.84      0.84        61\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, model.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "24d613abb60bb713089e3474e23323260e70b64b"
   },
   "source": [
    "<a id='section4'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "565395408d00bbd3dfeadea271ad01b14f84e472"
   },
   "source": [
    "# Tunning Model - Version 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rodarTunning(X_train, y_train, X_test, y_test, rf_classifier):\n",
    "    \n",
    "    param_grid = {'n_estimators': [50, 75, 100, 125, 150, 175],\n",
    "                  'min_samples_split':[2,4,6,8,10],\n",
    "                  'min_samples_leaf': [1, 2, 3, 4],\n",
    "                  'max_depth': [5, 10, 15, 20, 25]}\n",
    "\n",
    "    grid_obj = GridSearchCV(rf_classifier,\n",
    "                            iid=True,\n",
    "                            return_train_score=True,\n",
    "                            param_grid=param_grid,\n",
    "                            scoring='roc_auc',\n",
    "                            cv=10)\n",
    "\n",
    "    grid_fit = grid_obj.fit(X_train, y_train)\n",
    "    rf_opt = grid_fit.best_estimator_\n",
    "\n",
    "    print('='*20)\n",
    "    print(\"best params: \" + str(grid_obj.best_estimator_))\n",
    "    print(\"best params: \" + str(grid_obj.best_params_))\n",
    "    print('best score:', grid_obj.best_score_)\n",
    "    print('='*20)\n",
    "    \n",
    "    print(classification_report(y_test, rf_opt.predict(X_test)))\n",
    "\n",
    "    print('New Accuracy of Model on train set: {:.2f}'.format(rf_opt.score(X_train, y_train)*100))\n",
    "    print('New Accuracy of Model on test set: {:.2f}'.format(rf_opt.score(X_test, y_test)*100))\n",
    "\n",
    "    return rf_opt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================\n",
      "best params: RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
      "                       criterion='gini', max_depth=10, max_features='auto',\n",
      "                       max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
      "                       min_impurity_split=None, min_samples_leaf=3,\n",
      "                       min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "                       n_estimators=125, n_jobs=None, oob_score=False,\n",
      "                       random_state=7, verbose=0, warm_start=False)\n",
      "best params: {'max_depth': 10, 'min_samples_leaf': 3, 'min_samples_split': 2, 'n_estimators': 125}\n",
      "best score: 0.9244156669776504\n",
      "====================\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.86      0.86        35\n",
      "           1       0.81      0.81      0.81        26\n",
      "\n",
      "    accuracy                           0.84        61\n",
      "   macro avg       0.83      0.83      0.83        61\n",
      "weighted avg       0.84      0.84      0.84        61\n",
      "\n",
      "New Accuracy of Model on train set: 95.87\n",
      "New Accuracy of Model on test set: 83.61\n"
     ]
    }
   ],
   "source": [
    "rf_classifier = RandomForestClassifier(class_weight = \"balanced\", random_state=7)\n",
    "rf_opt = rodarTunning(X_train, y_train, X_test, y_test, rf_classifier)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tunning Model - Version 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dados com escalas diferentes - Aplicando MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler(feature_range=(0, 5))\n",
    "df_HR = dt\n",
    "HR_col = list(df_HR.columns)\n",
    "HR_col.remove('target')\n",
    "for col in HR_col:\n",
    "    df_HR[col] = df_HR[col].astype(float)\n",
    "    df_HR[[col]] = scaler.fit_transform(df_HR[[col]])\n",
    "df_HR['target'] = pd.to_numeric(df_HR['target'], downcast='float')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================\n",
      "best params: RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
      "                       criterion='gini', max_depth=5, max_features='auto',\n",
      "                       max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
      "                       min_impurity_split=None, min_samples_leaf=3,\n",
      "                       min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "                       n_estimators=150, n_jobs=None, oob_score=False,\n",
      "                       random_state=7, verbose=0, warm_start=False)\n",
      "best params: {'max_depth': 5, 'min_samples_leaf': 3, 'min_samples_split': 2, 'n_estimators': 150}\n",
      "best score: 0.9263678470290041\n",
      "====================\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.85      0.83      0.84        35\n",
      "         1.0       0.78      0.81      0.79        26\n",
      "\n",
      "    accuracy                           0.82        61\n",
      "   macro avg       0.82      0.82      0.82        61\n",
      "weighted avg       0.82      0.82      0.82        61\n",
      "\n",
      "New Accuracy of Model on train set: 92.98\n",
      "New Accuracy of Model on test set: 81.97\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df_HR.drop('target', 1), df_HR['target'], test_size = .2, random_state=10) #split the data\n",
    "rf_classifier = RandomForestClassifier(class_weight = \"balanced\", random_state=7)\n",
    "rf_opt2 = rodarTunning(X_train, y_train, X_test, y_test, rf_classifier)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tunning Model - Version 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Avaliando outros modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm, tree, linear_model, neighbors\n",
    "from sklearn import naive_bayes, ensemble, discriminant_analysis, gaussian_process\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn import feature_selection\n",
    "from sklearn import model_selection\n",
    "from sklearn import metrics\n",
    "\n",
    "def testarModelos(X_train, X_test, y_train, y_test):\n",
    "\n",
    "    models = []\n",
    "    models.append(('Logistic Regression', LogisticRegression(solver='liblinear', random_state=7,\n",
    "                                                             class_weight='balanced')))\n",
    "    models.append(('SVM', SVC(gamma='auto', random_state=7)))\n",
    "    models.append(('KNN', KNeighborsClassifier()))\n",
    "    models.append(('Decision Tree Classifier',\n",
    "                   DecisionTreeClassifier(random_state=7)))\n",
    "    models.append(('Gaussian NB', GaussianNB()))\n",
    "    models.append(('Xgboost', XGBClassifier(learning_rate=0.02, n_estimators=600, objective='binary:logistic',\n",
    "                    silent=True, nthread=1)))\n",
    "    models.append(('RandomForestClassifier', RandomForestClassifier(max_depth=5)))\n",
    "\n",
    "    acc_results = []\n",
    "    auc_results = []\n",
    "    names = []\n",
    "\n",
    "    col = ['Algorithm', 'ROC AUC Mean', 'ROC AUC STD', \n",
    "           'Accuracy Mean', 'Accuracy STD']\n",
    "    df_results = pd.DataFrame(columns=col)\n",
    "    i = 0\n",
    "\n",
    "    for name, model in models:\n",
    "        kfold = model_selection.KFold(\n",
    "            n_splits=10, random_state=7)  # 10-fold cross-validation\n",
    "\n",
    "        cv_acc_results = model_selection.cross_val_score(  # accuracy scoring\n",
    "            model, X_train, y_train, cv=kfold, scoring='accuracy')\n",
    "\n",
    "        cv_auc_results = model_selection.cross_val_score(  # roc_auc scoring\n",
    "            model, X_train, y_train, cv=kfold, scoring='roc_auc')\n",
    "\n",
    "        acc_results.append(cv_acc_results)\n",
    "        auc_results.append(cv_auc_results)\n",
    "        names.append(name)\n",
    "        df_results.loc[i] = [name,\n",
    "                             round(cv_auc_results.mean()*100, 2),\n",
    "                             round(cv_auc_results.std()*100, 2),\n",
    "                             round(cv_acc_results.mean()*100, 2),\n",
    "                             round(cv_acc_results.std()*100, 2)\n",
    "                             ]\n",
    "        i += 1\n",
    "    return df_results.sort_values(by=['ROC AUC Mean'], ascending=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  Algorithm  ROC AUC Mean  ROC AUC STD  Accuracy Mean  \\\n",
      "0       Logistic Regression         91.73         4.36          82.28   \n",
      "5                   Xgboost         91.52         6.94          82.33   \n",
      "6    RandomForestClassifier         88.46         6.77          81.47   \n",
      "4               Gaussian NB         87.91         7.34          79.78   \n",
      "1                       SVM         86.97         6.30          79.40   \n",
      "2                       KNN         86.65         8.03          80.63   \n",
      "3  Decision Tree Classifier         77.31         8.60          76.45   \n",
      "\n",
      "   Accuracy STD  \n",
      "0          5.97  \n",
      "5          8.16  \n",
      "6          6.99  \n",
      "4          6.71  \n",
      "1          6.35  \n",
      "2          4.98  \n",
      "3          6.69  \n",
      "                  Algorithm  ROC AUC Mean  ROC AUC STD  Accuracy Mean  \\\n",
      "0       Logistic Regression         91.73         4.36          82.28   \n",
      "5                   Xgboost         91.52         6.94          82.33   \n",
      "4               Gaussian NB         87.91         7.34          79.78   \n",
      "6    RandomForestClassifier         87.62         7.48          78.97   \n",
      "1                       SVM         86.97         6.30          79.40   \n",
      "2                       KNN         86.65         8.03          80.63   \n",
      "3  Decision Tree Classifier         77.31         8.60          76.45   \n",
      "\n",
      "   Accuracy STD  \n",
      "0          5.97  \n",
      "5          8.16  \n",
      "4          6.71  \n",
      "6          6.39  \n",
      "1          6.35  \n",
      "2          4.98  \n",
      "3          6.69  \n"
     ]
    }
   ],
   "source": [
    "#Sem MinMaxScaler\n",
    "X_train, X_test, y_train, y_test = train_test_split(dt.drop('target', 1), dt['target'], test_size = .2, random_state=10) \n",
    "df_results = testarModelos(X_train, X_test, y_train, y_test)\n",
    "print(df_results)\n",
    "\n",
    "#Com MinMaxScaler\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_HR.drop('target', 1), df_HR['target'], test_size = .2, random_state=10) \n",
    "df_results = testarModelos(X_train, X_test, y_train, y_test)\n",
    "print(df_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================\n",
      "best params: XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "              colsample_bynode=1, colsample_bytree=1, gamma=0,\n",
      "              learning_rate=0.02, max_delta_step=0, max_depth=10,\n",
      "              min_child_weight=1, min_samples_leaf=1, min_samples_split=2,\n",
      "              missing=None, n_estimators=175, n_jobs=1, nthread=None,\n",
      "              objective='binary:logistic', random_state=0, reg_alpha=0,\n",
      "              reg_lambda=1, scale_pos_weight=1, seed=None, silent=None,\n",
      "              subsample=1, verbosity=1)\n",
      "best params: {'max_depth': 10, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 175}\n",
      "best score: 0.9106463784149734\n",
      "====================\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.83      0.86      0.85        35\n",
      "         1.0       0.80      0.77      0.78        26\n",
      "\n",
      "    accuracy                           0.82        61\n",
      "   macro avg       0.82      0.81      0.81        61\n",
      "weighted avg       0.82      0.82      0.82        61\n",
      "\n",
      "New Accuracy of Model on train set: 99.17\n",
      "New Accuracy of Model on test set: 81.97\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(dt.drop('target', 1), dt['target'], test_size = .2, random_state=10) \n",
    "rf_classifier = XGBClassifier(learning_rate=0.02, objective='binary:logistic')\n",
    "rf_opt3 = rodarTunning(X_train, y_train, X_test, y_test, rf_classifier)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tunning 1 demonstrou melhor acurária e maior acertos nas 2 target (0 e 1)\n",
    "#### Tivemos um aumento de 3% no Treinamento e o mesmo resultado no Teste, mas pela métrica de matriz de confusão e relatório de classificação o acerto entre as classes foi equalizado, mais genérico. \n",
    "#### Não foi muita diferença na aplicação de escala no dataset, desta forma, foi ignorada. \n",
    "#### O modelo XGBClassifier aparece como promissor, mas para o case, vamos seguir com a decisão do Data Science (Autor) com o RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save Modelo Tunning Version 1 - Marcio de Lima\n",
    "import pickle\n",
    "\n",
    "filename = 'modelo/tunning_model.pkl'\n",
    "pickle.dump(rf_opt, open(filename, 'wb'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
